{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779fbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a89be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/dzxcw2k50f17832w60gvr9qw0000gn/T/ipykernel_11255/447338999.py:1: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  accepted = pd.read_csv('accepted.csv')\n"
     ]
    }
   ],
   "source": [
    "accepted = pd.read_csv('accepted.csv')\n",
    "\n",
    "selected_cols = [\n",
    "    'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
    "    'emp_title', 'emp_length', 'home_ownership', 'annual_inc',\n",
    "    'verification_status', 'purpose', 'dti', 'fico_range_low', 'fico_range_high',\n",
    "    'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'loan_status'\n",
    "]\n",
    "\n",
    "accepted_selected = accepted[selected_cols]\n",
    "\n",
    "\n",
    "# =====================[ IQR ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ ]=====================\n",
    "def remove_outliers_iqr(accepted_selected, cols):\n",
    "    for col in cols:\n",
    "        Q1 = accepted_selected[col].quantile(0.25)\n",
    "        Q3 = accepted_selected[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        mask = (accepted_selected[col] >= Q1 - 1.5*IQR) & (accepted_selected[col] <= Q3 + 1.5*IQR)\n",
    "        accepted_selected = accepted_selected[mask]\n",
    "    return accepted_selected.reset_index(drop=True)\n",
    "\n",
    "\n",
    "iqr_cols = ['loan_amnt', 'installment', 'annual_inc', 'dti',\n",
    "            'open_acc', 'revol_bal', 'revol_util', 'total_acc']\n",
    "\n",
    "\n",
    "accepted_filtered = remove_outliers_iqr(accepted_selected, iqr_cols)\n",
    "\n",
    "# ì»¬ëŸ¼ë³„ í—ˆìš© ê°’ ë²”ìœ„ë¡œ í•„í„°ë§\n",
    "accepted_filtered = accepted_filtered[\n",
    "    (accepted_filtered['int_rate'] >= 6) & (accepted_filtered['int_rate'] <= 31) &\n",
    "    (accepted_filtered['dti'] >= 0) & (accepted_filtered['dti'] <= 40) &\n",
    "    (accepted_filtered['annual_inc'] > 0) &\n",
    "    (accepted_filtered['revol_util'] >= 0) & (accepted_filtered['revol_util'] <= 100) &\n",
    "    (accepted_filtered['annual_inc'] > 0)\n",
    "]\n",
    "\n",
    "# 'emp_length' ê²°ì¸¡ê°’ì„ 'Unknown'ìœ¼ë¡œ ëŒ€ì²´\n",
    "accepted_filtered['emp_length'] = accepted_filtered['emp_length'].fillna('Unknown')\n",
    "\n",
    "# 'term' ì»¬ëŸ¼ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ ('36 months' â†’ 36)\n",
    "accepted_filtered['term'] = accepted_filtered['term'].astype(str).str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# 'grade' ë“±ê¸‰ì„ ë¬¸ìì—ì„œ ìˆ«ì ì½”ë“œ(0~6)ë¡œ ë³€í™˜ ('grade' ML ì‹œ ì¡”ì™¸)\n",
    "grade_map = {'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}\n",
    "accepted_filtered['grade_map'] = accepted_filtered['grade'].map(grade_map)\n",
    "\n",
    "# 'sub_grade' ë“±ê¸‰ì„ ë¬¸ìì—ì„œ ìˆ«ì ì½”ë“œ(0~34)ë¡œ ë³€í™˜ ('sub_grade' ML ì‹œ ì¡”ì™¸)\n",
    "import re\n",
    "\n",
    "accepted_filtered['sub_grade'] = accepted_filtered['sub_grade'].astype(str)\n",
    "\n",
    "def map_subgrade(sg):\n",
    "   try:\n",
    "       sg = str(sg).strip().upper()  \n",
    "       match = re.match(r'^([A-G])([1-5])$', sg) \n",
    "       if match:\n",
    "           letter = match.group(1)\n",
    "           number = int(match.group(2))\n",
    "           return grade_map[letter] * 5 + (5 - number)\n",
    "       else:\n",
    "           return None \n",
    "   except:\n",
    "       return None\n",
    "\n",
    "accepted_filtered['sub_grade_map'] = accepted_filtered['sub_grade'].apply(map_subgrade)\n",
    "\n",
    "# emp_length ë¬¸ìì—ì„œ ìˆ«ì ì½”ë“œ(0~10)ë¡œ ë³€í™˜ ('emp_length' ML ì‹œ ì¡”ì™¸)\n",
    "emp_length_map = {\n",
    "   '10+ years': 10,\n",
    "   '9 years': 9,\n",
    "   '8 years': 8,\n",
    "   '7 years': 7,\n",
    "   '6 years': 6,\n",
    "   '5 years': 5,\n",
    "   '4 years': 4,\n",
    "   '3 years': 3,\n",
    "   '2 years': 2,\n",
    "   '1 year': 1,\n",
    "   '< 1 year': 0.5,\n",
    "   'n/a': 0\n",
    "}\n",
    "\n",
    "\n",
    "accepted_filtered['emp_length_map'] = accepted_filtered['emp_length'].map(emp_length_map)\n",
    "\n",
    "# =====================[ log ë³€í™˜ (skewed ìˆ˜ì¹˜í˜•) ]=====================\n",
    "\n",
    "# ì™œë„(skew)ê°€ í° ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— ë¡œê·¸ ë³€í™˜ ì ìš©('annual_inc', 'revol_bal' ML ì‹œ ì œì™¸)\n",
    "accepted_filtered['annual_inc_log'] = np.log1p(accepted_filtered['annual_inc'])\n",
    "accepted_filtered['revol_bal_log'] = np.log1p(accepted_filtered['revol_bal'])\n",
    "\n",
    "\n",
    "\n",
    "accepted_filtered['fico_mean'] = (accepted_filtered['fico_range_low'] + accepted_filtered['fico_range_high']) / 2\n",
    "\n",
    "# ë ˆì´ë¸” ì¸ì½”ë”© ë”•ì…”ë„ˆë¦¬ ì˜ˆì‹œ (ì´ì§„ ë¶„ë¥˜)\n",
    "loan_status_map = {\n",
    "   'Fully Paid': 1,\n",
    "   'Current': 1,   # ë˜ëŠ” np.nanìœ¼ë¡œ ë‘ê³  ì œê±°í•  ìˆ˜ë„ ìˆìŒ\n",
    "   'Charged Off': 0,\n",
    "   'Late (31-120 days)': 0,\n",
    "   'Late (16-30 days)': 0,\n",
    "   'In Grace Period': 0,\n",
    "   'Does not meet the credit policy. Status:Fully Paid': 1,\n",
    "   'Does not meet the credit policy. Status:Charged Off': 0\n",
    "}\n",
    "# 'accepted_filtered'ì„ ì´ìš©í•  ë•Œ\n",
    "accepted_filtered['loan_status_f'] = accepted_filtered['loan_status'].map(loan_status_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4850f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ml = [\n",
    "   'int_rate', 'installment', 'purpose', 'dti', 'open_acc', 'revol_util',\n",
    "   'total_acc', 'emp_length_map', 'annual_inc_log', 'revol_bal_log', 'fico_mean',\n",
    "   'term', 'home_ownership', 'verification_status', 'purpose', 'loan_status_f'\n",
    "]\n",
    "\n",
    "accepted_ml = accepted_filtered[cols_ml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee306f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ê°’ì´ í¬í•¨ëœ í–‰ ì „ì²´ ì œê±°\n",
    "accepted_ml = accepted_ml.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0234c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°˜ë“œì‹œ í•œë²ˆë§Œ ì‹¤í–‰(ì—¬ëŸ¬ë²ˆ ì‹¤í–‰ í–ˆì„ ì‹œ accepted_ml ë“±ì¥í•  ë•Œë¶€í„° ë‹¤ì‹œ ëŒë¦¬ê¸°)\n",
    "accepted_ml = pd.get_dummies(\n",
    "   accepted_ml,\n",
    "   columns=['term', 'home_ownership', 'verification_status', 'purpose'],\n",
    "   drop_first=True,\n",
    "   dtype=int\n",
    ")\n",
    "\n",
    "accepted_ml = accepted_ml.loc[:, ~accepted_ml.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2b87263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í• \n",
    "df = accepted_ml.copy()  \n",
    "X = df.drop(columns='loan_status_f')\n",
    "y = df['loan_status_f']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# dtype ì •ì œ\n",
    "y_train = y_train.astype(int).reset_index(drop=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_valid = X_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97d733",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "271f0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: loan_status_f\n",
      "1    1145449\n",
      "0     182891\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: loan_status_f\n",
      "1    1145449\n",
      "0    1145449\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SMOTE ì ìš©\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c674344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.8247858229067859\n",
      "\n",
      "ğŸ“Š Confusion Matrix:\n",
      " [[  5703  39821]\n",
      " [ 18365 268196]]\n",
      "\n",
      "ğŸ“„ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.13      0.16     45524\n",
      "         1.0       0.87      0.94      0.90    286561\n",
      "\n",
      "    accuracy                           0.82    332085\n",
      "   macro avg       0.55      0.53      0.53    332085\n",
      "weighted avg       0.78      0.82      0.80    332085\n",
      "\n",
      "ğŸ¯ ROC AUC Score: 0.6331357439699553\n"
     ]
    }
   ],
   "source": [
    "# 2-1. SMOTE ì ìš© ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "\n",
    "# StandardScalerë¡œ ì •ê·œí™”\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# 1. ëª¨ë¸ ì •ì˜\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# 2. ëª¨ë¸ í•™ìŠµ\n",
    "logistic_model.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "# 3. ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡\n",
    "y_pred = logistic_model.predict(X_valid_scaled)\n",
    "y_proba = logistic_model.predict_proba(X_valid_scaled)[:, 1]  # í´ë˜ìŠ¤ 1ì— ëŒ€í•œ í™•ë¥ \n",
    "\n",
    "# 4. í‰ê°€ ì§€í‘œ ì¶œë ¥\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_valid, y_pred))\n",
    "print(\"\\nğŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n",
    "print(\"\\nğŸ“„ Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
    "print(\"ğŸ¯ ROC AUC Score:\", roc_auc_score(y_valid, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba2d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.8492584729813151\n",
      "\n",
      "ğŸ“Š Confusion Matrix:\n",
      " [[  2080  43444]\n",
      " [  6615 279946]]\n",
      "\n",
      "ğŸ“„ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.05      0.08     45524\n",
      "         1.0       0.87      0.98      0.92    286561\n",
      "\n",
      "    accuracy                           0.85    332085\n",
      "   macro avg       0.55      0.51      0.50    332085\n",
      "weighted avg       0.78      0.85      0.80    332085\n",
      "\n",
      "ğŸ¯ ROC AUC Score: 0.5266414845106044\n"
     ]
    }
   ],
   "source": [
    "# 2-2. SMOTE ì ìš© ëœë¤í¬ë ˆìŠ¤íŠ¸\n",
    "\n",
    "# 1. ëª¨ë¸ ì •ì˜\n",
    "randomforest_model = RandomForestClassifier(\n",
    "    n_estimators=100,     \n",
    "    max_depth=None,    \n",
    "    random_state=42,     \n",
    "    n_jobs=-1           \n",
    ")\n",
    "\n",
    "# 2. ëª¨ë¸ í•™ìŠµ\n",
    "randomforest_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡\n",
    "y_pred = randomforest_model.predict(X_valid)\n",
    "y_proba = randomforest_model.predict_proba(X_valid_scaled)[:, 1]  # í´ë˜ìŠ¤ 1ì— ëŒ€í•œ í™•ë¥ \n",
    "\n",
    "# 4. ì„±ëŠ¥ í‰ê°€\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_valid, y_pred))\n",
    "print(\"\\nğŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n",
    "print(\"\\nğŸ“„ Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
    "print(\"ğŸ¯ ROC AUC Score:\", roc_auc_score(y_valid, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8599b9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.8483550898113434\n",
      "\n",
      "ğŸ“Š Confusion Matrix:\n",
      " [[  1611  43913]\n",
      " [  6446 280115]]\n",
      "\n",
      "ğŸ“„ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.04      0.06     45524\n",
      "         1.0       0.86      0.98      0.92    286561\n",
      "\n",
      "    accuracy                           0.85    332085\n",
      "   macro avg       0.53      0.51      0.49    332085\n",
      "weighted avg       0.77      0.85      0.80    332085\n",
      "\n",
      "ğŸ¯ ROC AUC Score: 0.530892824515436\n"
     ]
    }
   ],
   "source": [
    "# 2-3. SMOTE ì ìš© XGBOOST\n",
    "\n",
    "# 1. ëª¨ë¸ ì •ì˜\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,        \n",
    "    learning_rate=0.1,      \n",
    "    max_depth=6,              \n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1                \n",
    ")\n",
    "\n",
    "\n",
    "# 2. ëª¨ë¸ í•™ìŠµ\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y_pred = xgb_model.predict(X_valid)\n",
    "y_proba = xgb_model.predict_proba(X_valid_scaled)[:, 1]  # í´ë˜ìŠ¤ 1ì— ëŒ€í•œ í™•ë¥ \n",
    "\n",
    "# 4. í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_valid, y_pred))\n",
    "print(\"\\nğŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n",
    "print(\"\\nğŸ“„ Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
    "print(\"ğŸ¯ ROC AUC Score:\", roc_auc_score(y_valid, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ee8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1145449, number of negative: 1145449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2584\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290898, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.8516313594411069\n",
      "\n",
      "ğŸ“Š Confusion Matrix:\n",
      " [[  1313  44211]\n",
      " [  5060 281501]]\n",
      "\n",
      "ğŸ“„ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.21      0.03      0.05     45524\n",
      "         1.0       0.86      0.98      0.92    286561\n",
      "\n",
      "    accuracy                           0.85    332085\n",
      "   macro avg       0.54      0.51      0.49    332085\n",
      "weighted avg       0.77      0.85      0.80    332085\n",
      "\n",
      "ğŸ¯ ROC AUC Score: 0.5141773599106432\n"
     ]
    }
   ],
   "source": [
    "# 2-4. SMOTE ì ìš© LIGHT GBM\n",
    "\n",
    "# 1. ëª¨ë¸ ì •ì˜\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. ëª¨ë¸ í•™ìŠµ\n",
    "lgbm_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 3. ì˜ˆì¸¡\n",
    "y_pred = lgbm_model.predict(X_valid)\n",
    "y_proba = lgbm_model.predict_proba(X_valid_scaled)[:, 1]  # í´ë˜ìŠ¤ 1ì— ëŒ€í•œ í™•ë¥ \n",
    "\n",
    "# 4. í‰ê°€\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_valid, y_pred))\n",
    "print(\"\\nğŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n",
    "print(\"\\nğŸ“„ Classification Report:\\n\", classification_report(y_valid, y_pred))\n",
    "print(\"ğŸ¯ ROC AUC Score:\", roc_auc_score(y_valid, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0446e3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.13      0.16     45524\n",
      "         1.0       0.87      0.94      0.90    286561\n",
      "\n",
      "    accuracy                           0.82    332085\n",
      "   macro avg       0.55      0.53      0.53    332085\n",
      "weighted avg       0.78      0.82      0.80    332085\n",
      "\n",
      "ROC AUC Score: 0.6331058485346761\n"
     ]
    }
   ],
   "source": [
    "# LR í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# GridSearchì— ì ìš©\n",
    "lr_grid = GridSearchCV(\n",
    "    lr_pipeline,\n",
    "    {\n",
    "        'clf__C': [0.01, 0.1, 1, 10],\n",
    "        'clf__penalty': ['l2'],\n",
    "        'clf__class_weight': ['balanced', None],\n",
    "        'clf__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = lr_grid.best_estimator_.predict(X_valid)\n",
    "y_proba = lr_grid.best_estimator_.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_valid, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718910dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n    r = call_item()\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py\", line 607, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\", line 487, in fit\n    trees = Parallel(\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py\", line 2072, in __call__\n    return output if self.return_generator else list(output)\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py\", line 1682, in _get_outputs\n    yield from self._retrieve()\n  File \"/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py\", line 1800, in _retrieve\n    time.sleep(0.01)\nKeyboardInterrupt\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:1859\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:758\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:773\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 773\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m      3\u001b[0m rf_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m     10\u001b[0m rf_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     11\u001b[0m     RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     12\u001b[0m     rf_param_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[43mrf_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf_grid\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n\u001b[1;32m     21\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m rf_grid\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:1732\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1732\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_abort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:1646\u001b[0m, in \u001b[0;36mParallel._abort\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabort_everything\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n\u001b[0;32m-> 1646\u001b[0m     \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabort_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/_parallel_backends.py:725\u001b[0m, in \u001b[0;36mLokyBackend.abort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mabort_everything\u001b[39m(\u001b[38;5;28mself\u001b[39m, ensure_ready\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    724\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\"\"\"\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_ready:\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/executor.py:86\u001b[0m, in \u001b[0;36mMemmappingExecutor.terminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mterminate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kill_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkill_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# on by the resource_tracker.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock:\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:1333\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# is shutting down.\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _global_shutdown_lock:\n\u001b[0;32m-> 1333\u001b[0m         \u001b[43mexecutor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m         _threads_wakeups\u001b[38;5;241m.\u001b[39mpop(executor_manager_thread, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RandomForest í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 10, None],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "y_pred = rf_grid.best_estimator_.predict(X_valid)\n",
    "y_proba = rf_grid.best_estimator_.predict_proba(X_valid)[:, 1]\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_valid, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba50693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:00:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:01:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:01:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:01:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:01:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:02:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:03:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:03:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:03:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:04:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:04:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:04:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:04:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:04:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:05:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:05:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:05:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:05:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:06:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:07:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:08:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:09:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:10:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:10:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/t2023-m0051/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:11:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.16      0.01      0.01     45524\n",
      "         1.0       0.86      0.99      0.92    286561\n",
      "\n",
      "    accuracy                           0.86    332085\n",
      "   macro avg       0.51      0.50      0.47    332085\n",
      "weighted avg       0.77      0.86      0.80    332085\n",
      "\n",
      "ROC AUC Score: 0.6915839849023464\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "neg, pos = np.bincount(y_train_res)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'scale_pos_weight': [scale_pos_weight, scale_pos_weight*1.5]\n",
    "}\n",
    "\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', n_jobs=-1),\n",
    "    xgb_param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "y_pred = xgb_grid.best_estimator_.predict(X_valid)\n",
    "y_proba = xgb_grid.best_estimator_.predict_proba(X_valid)[:, 1]\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_valid, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "061a59e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m      8\u001b[0m lgb_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale_pos_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [scale_pos_weight, scale_pos_weight\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.5\u001b[39m]\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     18\u001b[0m lgb_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     19\u001b[0m     LGBMClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     20\u001b[0m     lgb_param_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mlgb_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m lgb_grid\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n\u001b[1;32m     29\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m lgb_grid\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/5mygod_project/smote/lib/python3.10/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LightGBM í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "# is_unbalanceì™€ scale_pos_weightë¥¼ ë™ì‹œì— ì„¤ì •í•˜ë©´ ì•ˆ ë¨ - ì¼ë°˜ ì‹¤ë¬´ì„  scale_pos_weight ì¶”ì²œ\n",
    "\n",
    "neg, pos = np.bincount(y_train_res)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    # 'is_unbalance': [True],   # <= ì´ ë¶€ë¶„ ì œê±°!\n",
    "    'scale_pos_weight': [scale_pos_weight, scale_pos_weight*1.5]\n",
    "}\n",
    "\n",
    "\n",
    "lgb_grid = GridSearchCV(\n",
    "    LGBMClassifier(random_state=42, n_jobs=-1),\n",
    "    lgb_param_grid,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgb_grid.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "y_pred = lgb_grid.best_estimator_.predict(X_valid)\n",
    "y_proba = lgb_grid.best_estimator_.predict_proba(X_valid)[:, 1]\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_valid, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70939259",
   "metadata": {},
   "source": [
    "CatBoost, Decision Tree, SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8bc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboostì´ë¯€ë¡œ ëª…ëª©í˜• ë³€ìˆ˜ ìˆ«ìí˜• ë³€ìˆ˜ë¡œ ë³€í™˜í•˜ì§€ ì•ŠëŠ” accepted_cat ë§Œë“¤ê¸°\n",
    "cols_cat = [\n",
    "  'int_rate', 'installment', 'purpose', 'dti', 'open_acc', 'revol_util',\n",
    "  'total_acc', 'emp_length_map', 'annual_inc_log', 'revol_bal_log', 'fico_mean',\n",
    "  'term', 'home_ownership', 'verification_status', 'loan_status_f'\n",
    "]\n",
    "\n",
    "accepted_cat = accepted_filtered[cols_cat]\n",
    "\n",
    "# ê²°ì¸¡ê°’ì´ í¬í•¨ëœ í–‰ ì „ì²´ ì œê±°\n",
    "accepted_cat = accepted_cat.dropna().reset_index(drop=True)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "df = accepted_cat.copy()  \n",
    "X = df.drop(columns='loan_status_f')\n",
    "y = df['loan_status_f']\n",
    "\n",
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# dtype ì •ì œ\n",
    "y_train2 = y_train2.astype(int).reset_index(drop=True)\n",
    "X_train2 = X_train2.reset_index(drop=True)\n",
    "X_valid2 = X_valid2.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f72e7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.69      0.34     45524\n",
      "         1.0       0.93      0.62      0.74    286561\n",
      "\n",
      "    accuracy                           0.63    332085\n",
      "   macro avg       0.58      0.66      0.54    332085\n",
      "weighted avg       0.83      0.63      0.69    332085\n",
      "\n",
      "ROC AUC Score: 0.7165524217071628\n"
     ]
    }
   ],
   "source": [
    "# 1. CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# ë²”ì£¼í˜• ì»¬ëŸ¼\n",
    "cat_cols = ['purpose', 'home_ownership', 'verification_status', 'term']\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "classes = np.unique(y_train2)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train2)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# CatBoost ëª¨ë¸ ì •ì˜\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    class_weights=class_weights,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "cat_model.fit(X_train2, y_train2, cat_features=cat_cols)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred2 = cat_model.predict(X_valid2)\n",
    "y_proba2 = cat_model.predict_proba(X_valid2)[:, 1]\n",
    "\n",
    "print(\"CatBoost\")\n",
    "print(classification_report(y_valid2, y_pred2))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_valid2, y_proba2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52087611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.25      0.22     45524\n",
      "         1.0       0.88      0.84      0.86    286561\n",
      "\n",
      "    accuracy                           0.76    332085\n",
      "   macro avg       0.54      0.54      0.54    332085\n",
      "weighted avg       0.78      0.76      0.77    332085\n",
      "\n",
      "ROC AUC Score: 0.6332740664506775\n"
     ]
    }
   ],
   "source": [
    "# 2. Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Decision Tree ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=6,\n",
    "    class_weight='balanced',  # ë¶ˆê· í˜• ë°ì´í„°ì¼ ê²½ìš°\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = dt_model.predict(X_valid)\n",
    "y_proba = dt_model.predict_proba(X_valid)[:, 1]\n",
    "print(\"Decision Tree\")\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_valid, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SVM (Support Vector Machine)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# SVM ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "svm_model = SVC(\n",
    "    C=1.0,           # ì •ê·œí™” íŒŒë¼ë¯¸í„°\n",
    "    kernel='rbf',    # RBF(ê°€ìš°ì‹œì•ˆ) ì»¤ë„\n",
    "    class_weight='balanced',\n",
    "    probability=True, # predict_proba ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”\n",
    "    random_state=42\n",
    ")\n",
    "svm_model.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = svm_model.predict(X_valid_scaled)\n",
    "y_proba = svm_model.predict_proba(X_valid_scaled)[:, 1]\n",
    "print(\"SVM\")\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_valid, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b153b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1844829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46588e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6364894",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef4d07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
